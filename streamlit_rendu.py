#Projet Data Analyse sur le Bien-Etre - r√©alis√© par Lodaodav√© LEMA, Ga√´lle MARINESQUE, H√©l√®ne KHALIDI et Patrick BOUK√â 
#DataScientest CDA Juin 2024. 
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor, plot_tree, export_graphviz
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from xgboost import XGBRegressor
from sklearn import tree
import graphviz
import io
import plotly.graph_objects as go

@st.cache_data
def load_data():
    try:
        data = pd.read_csv("happycommun1.csv")
        data_avant = pd.read_csv("happy_avant_fusion.csv")
        return data, data_avant
    except FileNotFoundError:
        st.error("Le fichier 'happycommun1.csv' est introuvable")
        return None 

data, data_avant = load_data()


st.sidebar.image("https://myfiteo.app/src_img_happy/img0.png", use_column_width=True)
st.sidebar.markdown("<h1 style='font-weight:normal; color:#000000;'><b>Le Bonheur dans le monde</b></h1>", unsafe_allow_html=True)
st.sidebar.markdown('<hr>', unsafe_allow_html=True)
menu = st.sidebar.radio("",["Introduction", "Hypoth√®ses", "Sources", "Visualisation", "Mod√©lisation", "Analyse Machine Learning", "Conclusion"])
st.sidebar.markdown('<hr>', unsafe_allow_html=True)
st.sidebar.markdown("<h4>üåç Projet r√©alis√© par:</h4>  <p>Lodav√© LEMA, Ga√´lle MARINESQUE, <br>H√©l√®ne KHALIDI et Patrick BOUK√â</p><h4>Promotion DA - Juin 2024</h4>", unsafe_allow_html=True)   

if data is not None:  

    

    if menu == "Introduction":
        st.image("https://myfiteo.app/src_img_happy/img3.png", use_column_width=True)
        
        
        st.markdown(
        """
        <h1 style="
            font-size: 2em; 
            margin: 0; 
            padding: 0;">
            Analyse du Bonheur et du Bien-√™tre
        </h1><br>
        <p align="justify"><i>La recherche du bonheur est certainement la plus grande qu√™te de l‚Äôhumanit√©. Nous cherchons tous √† √™tre heureux. L‚Äôanalyse des indices de bonheur nous offre un aper√ßu pr√©cieux de ce qui rend les individus et les soci√©t√©s r√©ellement √©panouis. Gr√¢ce aux donn√©es, nous ne nous contentons pas de mesurer un sentiment subjectif‚ÄØ: nous identifions les tendances, comprenons les disparit√©s et r√©v√©lons les leviers qui favorisent un bien-√™tre durable.</i></p>

        <br>
        <br>
        """,
        unsafe_allow_html=True)
        
        tab1, tab2 = st.tabs(["Probl√©matique", "Recherches principales"])

        

        with tab1:
            st.markdown("### Probl√©matique", unsafe_allow_html=True)
            st.markdown("""<p align="justify">Le bonheur des populations est un indicateur complexe et multidimensionnel qui va bien au-del√† des simples mesures √©conomiques. Il int√®gre des dimensions sociales, √©conomiques et politiques qui interagissent de mani√®re complexe pour influencer le bien-√™tre global des individus. Cette √©tude cherche √† approfondir la compr√©hension de ces facteurs et √† d√©terminer comment ils contribuent aux variations de bonheur entre les pays sur la p√©riode de 2005 √† 2023.</p>""",unsafe_allow_html=True)

        with tab2:
            st.markdown("### Questions de recherches principales", unsafe_allow_html=True)
            st.markdown("1. Quels sont les principaux facteurs sociaux, √©conomiques et politiques qui influencent le bonheur mondial ?",unsafe_allow_html=True)
            st.markdown("2. Comment ces facteurs ont-ils √©volu√© √† travers le temps en Europe ?",unsafe_allow_html=True)
            st.markdown("3. L'argent fait-il le bonheur ?",unsafe_allow_html=True)

    
    elif menu == "Hypoth√®ses":
        st.image("https://myfiteo.app/src_img_happy/img2.png", use_column_width=True)
    
        st.markdown("<h1>Hypoth√®ses</h1>", unsafe_allow_html=True)
    
        
        tab1, tab2 = st.tabs(["Hypoth√®ses g√©n√©rales", "Hypoth√®ses sp√©cifiques"])
    
        with tab1:
            st.markdown("### Hypoth√®ses g√©n√©rales (au niveau mondial)", unsafe_allow_html=True)
            st.markdown("1. Les variables √©conomiques telles que le PIB par habitant ont un impact significatif sur le bonheur des populations.", unsafe_allow_html=True)
            st.markdown("2. Les variables sociales, telles que l'accompagnement social et l'esp√©rance de vie en bonne sant√©, jouent un r√¥le crucial dans la satisfaction de vie des individus.", unsafe_allow_html=True)
            st.markdown("3. Les dimensions de la libert√© (√©conomique, personnelle et choix de vie) influencent positivement le bonheur mondial.", unsafe_allow_html=True)
            st.markdown("4. La perception de la corruption et les affects positifs et n√©gatifs sont √©galement des d√©terminants importants du bonheur.", unsafe_allow_html=True)
            st.markdown("5. Les tendances annuelles du bonheur montrent des variations significatives entre les continents, influenc√©es par des facteurs r√©gionaux sp√©cifiques.", unsafe_allow_html=True)
    
        with tab2:
            st.markdown("### Hypoth√®ses sp√©cifiques (concentr√©es sur l'Europe)", unsafe_allow_html=True)
            st.markdown("1. En Europe, les facteurs sociaux tels que le soutien social et les politiques de protection sociale ont un impact plus prononc√© sur le bonheur par rapport aux autres r√©gions du monde.", unsafe_allow_html=True)
            st.markdown("2. En Europe, les niveaux √©lev√©s de libert√© √©conomique et personnelle sont fortement corr√©l√©s avec des niveaux √©lev√©s de satisfaction de vie.", unsafe_allow_html=True)
            st.markdown("3. Les interactions entre les variables √©conomiques (PIB, libert√© √©conomique), sociales (soutien social, sant√©) et politiques (perception de la corruption) expliquent en grande partie les variations de bonheur entre les pays europ√©ens.", unsafe_allow_html=True)



    elif menu == "Sources":
        st.image("https://myfiteo.app/src_img_happy/img1.png", use_column_width=True)
        
        st.markdown(
        """
        <h1 style="
            font-size: 2em; 
            margin: 0; 
            padding: 0;">
            Sources
        </h1>
        """,
        unsafe_allow_html=True)
        
        tab1, tab2, tab3, tab4 = st.tabs(["Donn√©es initiales", "Aper√ßu des donn√©es", "Donn√©es compl√©mentaires", "Aper√ßu des donn√©es fusionn√©es"])

        with tab1:
            st.markdown("### Donn√©es initiales", unsafe_allow_html=True)
            st.markdown("""<p align="justify">Dans le cadre de l‚Äôanalyse exploratoire nous avons eu acc√®s √† une base de donn√©es (DataForTable2.1.xls) disponible librement sur <a href="https://worldhappiness.report/data/">le site web World Happiness</a> des Nations Unies. Elle regroupe diff√©rentes enqu√™tes r√©alis√©es √† travers le monde :</p>""", unsafe_allow_html=True)
            st.markdown("  - Note de bonheur (Life Ladder)", unsafe_allow_html=True)
            st.markdown("  - PIB par habitant (Log GDP per capita)", unsafe_allow_html=True)
            st.markdown("  - Support social (Social support)", unsafe_allow_html=True)
            st.markdown("  - Esp√©rance de vie √† la naissance (Healthy life expectancy at birth)", unsafe_allow_html=True)
            st.markdown("  - Libert√© de faire des choix de vie (Freedom to make life choices)", unsafe_allow_html=True)
            st.markdown("  - G√©n√©rosit√© (Generosity)", unsafe_allow_html=True)
            st.markdown("  - Perception de la corruption (Perceptions of corruption)", unsafe_allow_html=True)
            st.markdown("  - Affects positifs et n√©gatifs (Positive affect / Negative affect)", unsafe_allow_html=True)

        with tab2:
            st.markdown("### Aper√ßu des donn√©es", unsafe_allow_html=True)
            st.dataframe(data_avant.head(5))

        with tab3:
            st.markdown("### Donn√©es compl√©mentaires", unsafe_allow_html=True)
            st.markdown("""<p align="justify">Pour enrichir la base de donn√©es, une nouvelle enqu√™te (2023-Human-Freedom-Index-Data.xls) a √©t√© int√©gr√©e depuis <a href="https://www.cato.org/human-freedom-index/2023">le site web Cato Institute</a>. Elle apporte une notion diff√©rente dans cette analyse. Celle-ci note la libert√© humaine au travers de 2 grands principes :</p>""", unsafe_allow_html=True)
            st.markdown("  - Libert√© personnelle (PERSONAL FREEDOM) avec les aspects l√©gaux, s√©curit√©, mouvement des individus, religion, politique et presse.", unsafe_allow_html=True)
            st.markdown("  - Libert√© √©conomique (ECONOMIC FREEDOM) avec les aspects d‚Äôordre politiques, √©galit√© hommes/femmes, mon√©taire, √©changes internationaux et r√®glementation du travail.", unsafe_allow_html=True)
            st.markdown("Il para√Æt pertinent d‚Äôinclure les notes de libert√© personnelle et de libert√© √©conomique car elles d√©coulent de donn√©es issues d‚Äô√©tudes concr√®tes et pertinentes par rapport √† l‚Äôanalyse du bonheur.", unsafe_allow_html=True)

        with tab4:
            st.markdown("### Aper√ßu des donn√©es fusionn√©es", unsafe_allow_html=True)
            st.dataframe(data.head(5))

    
    
    elif menu == "Visualisation":
        
    
        #st.image("https://myfiteo.app/src_img_happy/img4.png", use_column_width=True)
        st.markdown("<h1>Visualisation des Donn√©es</h1>", unsafe_allow_html=True)
        st.markdown("<h3>Au niveau Mondial</h3>", unsafe_allow_html=True)
        st.image("https://myfiteo.app/src_img_happy/img9.png", use_column_width=True)
        
        
    
        # Section Carte Interactive
        with st.expander("Carte interactive de l'indice de bonheur par pays", expanded=False):
            if "year" in data.columns and "Country name" in data.columns and "Life Ladder" in data.columns:
                st.markdown("### Evolution de l'indice de bonheur par pays")
                happy_by_year = data.sort_values(by="year")
                
                fig = px.choropleth(
                    happy_by_year,
                    locations="Country name",
                    locationmode="country names",
                    color="Life Ladder",
                    color_continuous_scale="rainbow",
                    animation_frame="year",
                    labels={"year": "Ann√©e"},
                    range_color=[0, 10]
                )
                
                fig.update_layout(
                    geo=dict(showframe=False, showcoastlines=True, projection_type='miller'),
                    coloraxis_colorbar=dict(title="Life Ladder"),
                    width=800,
                    height=800
                )
                
                st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': True, 'displayModeBar': False})
            else:
                st.error("Les colonnes n√©cessaires pour cr√©er la carte interactive sont manquantes.")
    
        # Section Heatmap des Corr√©lations
        with st.expander("Heatmap des Corr√©lations"):
            st.markdown("<h4>Corr√©lation entre le bonheur (life ladder) et les autres indicateurs</h4>", unsafe_allow_html=True)
            
            if data is not None:
                num = data.iloc[:, 4:15].corr()
                fig, ax = plt.subplots(figsize=(10, 10))
                sns.heatmap(num, annot=True, ax=ax, cmap='rainbow')
                st.pyplot(fig)
    
        # Section Boxplot
        with st.expander("V√©rification des valeurs extr√™mes avec les Boxplots"):
            if data is not None:
                happyfiltre = data.dropna(subset=['Life Ladder', 'Economic Freedom', 'Log GDP per capita', 'Social support', 'Healthy life expectancy at birth'])
                happyfiltre = happyfiltre[~happyfiltre['year'].isin([2005, 2022, 2023])].round(3)
                happyfiltre['Social support'] = happyfiltre['Social support'] * 10
                happyfiltre["Healthy life expectancy at birth"] = happyfiltre["Healthy life expectancy at birth"]/10
    
                st.markdown("<h4>V√©rification des valeurs extr√™mes de ces variables</h4>", unsafe_allow_html=True)
                st.markdown("""<p align="justify"><b>Social Support : </b> Ces valeurs extr√™mes pourraient correspondre √† des pays ou des r√©gions o√π le soutien social est significativement moins d√©velopp√© ou peu accessible.<br><br><b>Healthy Life Expectancy at Birth :</b> Ces valeurs extr√™mes faibles peuvent √™tre associ√©es √† des pays en d√©veloppement ou √† des r√©gions confront√©es √† des d√©fis sanitaires majeurs. Cette disparit√© importante est probablement influenc√©e par des facteurs comme l'acc√®s aux soins, la qualit√© de vie et les infrastructures sanitaires.<br></p>""", unsafe_allow_html=True)
                col = ['Life Ladder', 'Economic Freedom', 'Log GDP per capita', 'Social support', 'Healthy life expectancy at birth']
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.boxplot(data=happyfiltre[col], ax=ax, color="#4498e8")
                #ax.set_title("Boxplots des Variables √©conomiques et sociales")
                st.pyplot(fig)
    
        # Section Moyenne des Variables par Continent
        with st.expander("Moyenne des variables par continent"):
            if data is not None:
                moyenne_par_continent = happyfiltre.groupby('Continent')[['Life Ladder', 'Economic Freedom', 'Log GDP per capita', 'Social support', 'Healthy life expectancy at birth']].mean().reset_index()
                data_melted = moyenne_par_continent.melt(id_vars='Continent', var_name='Variable', value_name='Moyenne')
    
                st.markdown("### Moyenne des variables par continent", unsafe_allow_html=True)
                st.markdown("""<p align="justify">Les continents Oc√©anie, Am√©rique et Europe, b√©n√©ficient des meilleurs indices  de bonheur (Life Ladder), de libert√© √©conomique (Economic Freedom), de PIB par habitant (Log GDP per capita) et de soutien social (Social support). On peut remarquer que sur certaines variables l‚ÄôEurope est talonn√©e par l‚ÄôAm√©rique du Sud.</p>""", unsafe_allow_html=True)
                
                fig, ax = plt.subplots(figsize=(14, 8))
                sns.barplot(data=data_melted, x='Continent', y='Moyenne', hue='Variable', palette='rainbow', ax=ax)
                ax.grid(True, which='both', linestyle='--', linewidth= 0.7)
                #ax.set_title("Moyenne des variables par continent", fontsize=16)
                plt.tight_layout()
                st.pyplot(fig)
    
        # Section √âvolution par Continent
        with st.expander("√âvolution de l'indice du bonheur par continent"):
            st.markdown("### √âvolution du bonheur par continent")
            st.markdown("Ce graphique permet de comparer l‚Äô√©volution de l‚Äôindice du bonheur au fil des ann√©es entre les continents")
            moy_continent_an = happyfiltre.groupby(['Continent', 'year'])[['Life Ladder', 'Economic Freedom', 'Log GDP per capita', 'Social support', 'Healthy life expectancy at birth']].mean().reset_index()
            fig = px.line(
                moy_continent_an,
                x="year",
                y="Life Ladder",
                color="Continent",
                markers=True,
                labels={"year": "Ann√©e", "Life Ladder": "Indice de bonheur", "Continent": "Continent"}
            )
            fig.update_layout(width=1000, height=600, template="plotly_white", xaxis=dict(tickmode="linear", dtick=1))
            
            st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': False, 'displayModeBar': False})

        
        st.markdown("<h3>Au niveau Europ√©en</h3>", unsafe_allow_html=True)
        st.image("https://myfiteo.app/src_img_happy/img12.png", use_column_width=True)

        
        # Section √âvolution en Europe
        with st.expander("√âvolution de l'indice de bonheur en Europe"):
            happy_europe = happyfiltre[happyfiltre['Continent'] == 'Europe'].sort_values(by='year')
            happy_europe = happy_europe.groupby(['Continent', 'Regional indicator', 'year'])[['Life Ladder', 'Log GDP per capita', 'Economic Freedom', 'Social support', 'Healthy life expectancy at birth']].mean(numeric_only=True).reset_index()
        
            
            st.markdown("### √âvolution de l'indice de bonheur en Europe")
            st.markdown(
            """
            <style>
                .year {
                    color: #383838;
                    font-weight: bold;
                }
                .pin {
                    display: inline-block;
                    width: 10px;
                    height: 10px;
                    background-color: #ec5a53;
                    border-radius: 50%;
                    margin-right: 8px;
                    
                }
            </style>
            <div>
                <div><span class="year">Rep√®res:</span></div>
                <div><span class="pin"></span><span class="year">2008 :</span> Pr√©-crises des subprimes, perception d‚Äôune prosp√©rit√© continue, croissance √©conomique soutenue, stabilit√© √©conomique. D‚Äôautres facteurs ont pu influencer l‚Äôindice du bonheur, ex : JO de P√©kin (un sentiment de fiert√© collective et une perception positive de la soci√©t√©).</div>
                <div><span class="pin"></span><span class="year">2009 :</span> Cons√©quence de la crise √©conomique sur le bonheur.</div>
                <div><span class="pin"></span><span class="year">2010 :</span> Pic en Europe du Nord pouvant √™tre expliqu√© par la mise en place de politiques √©conomiques, sociales et √©cologiques renfor√ßant le sentiment de bien-√™tre g√©n√©ral.</div>
                <div><span class="pin"></span><span class="year">2020 ‚Äì 2022 :</span> COVID.</div>
            </div>
            """,
            unsafe_allow_html=True)
            custom_palette = ['#FF5733', '#33FF57', '#3357FF', '#FFC300','#DAF7A6']
            fig = px.line(
                happy_europe,
                x="year",
                y="Life Ladder",
                color="Regional indicator",
                markers=True,
                color_discrete_sequence=custom_palette,
                #title="√âvolution de l'indice de bonheur par sous-r√©gions europ√©ennes",
                labels={"year": "√âvolution de l'indice de bonheur par sous-r√©gions europ√©ennes", "Life Ladder": "Indice de bonheur", "Regional indicator": "Sous-r√©gions"}
            )
            fig.update_layout(
                width=800,
                height=400,
                legend_title_text="Sous-r√©gions",
                template="plotly_white",
                xaxis=dict(tickmode="linear", tick0=2005, dtick=1)
            )
            
            st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': False, 'displayModeBar': False})
    
        # Section √âvolution des Variables en Europe
        with st.expander("√âvolution des variables au fil du temps en Europe"):
            happy_EU_variable = happy_europe.groupby(['Continent', 'year'])[['Life Ladder', 'Economic Freedom', 'Log GDP per capita', 'Social support', 'Healthy life expectancy at birth']].mean(numeric_only=True).reset_index()
            
                
            data_long = happy_EU_variable.melt(
                id_vars="year", 
                value_vars=["Life Ladder", "Log GDP per capita", "Economic Freedom", "Social support", 'Healthy life expectancy at birth'], 
                var_name="Variable", 
                value_name="Value"
            )
        
            
            st.markdown("### √âvolution des variables au fil du temps en Europe")
            st.markdown("Les variables sont globalement stables")
            custom_palette2 = ['#FF5733', '#33FF57', '#3357FF', '#FFC300','#DAF7A6']
            fig = px.line(
                data_long,
                x="year",
                y="Value",
                color="Variable",
                markers=True,
                color_discrete_sequence=custom_palette2,
                title="",
                labels={"Value": "Valeurs Moyennes", "year": "√âvolution des variables au fil du temps en Europe", "Variable": "Variables"}
            )
            fig.update_layout(
                width=800, 
                height=400, 
                legend=dict(title="Variables"),
                xaxis=dict(tickmode="linear", tick0=2005, dtick=1),
                template="plotly_white",
            )
            
            st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': False, 'displayModeBar': False})
        
       

    

    elif menu == "Mod√©lisation":
        st.image("https://myfiteo.app/src_img_happy/img8.png", use_column_width=True)
        st.markdown("<h1>Mod√©lisation</h1>", unsafe_allow_html=True)
        st.markdown('<hr>', unsafe_allow_html=True)
    
        
        try:
            happyeurope = pd.read_csv('happycommun1.csv')
            happyeurope = happyeurope.loc[happyeurope['Continent']=='Europe'].drop('Continent', axis=1)
        except Exception as e:
            st.error(f"Erreur lors du chargement des donn√©es : {str(e)}")
            st.stop()
    
        try:
            # Pr√©paration des donn√©es
            feats = happyeurope.drop('Life Ladder', axis=1)
            target = happyeurope['Life Ladder']
    
            # Split des donn√©es
            X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.25, random_state=42)
    
            # Traitement des donn√©es manquantes et preprocessing
            def preprocess_data(X_train, X_test):
                columns_to_impute = [
                    'Log GDP per capita', 'Social support', 'Healthy life expectancy at birth',
                    'Freedom to make life choices', 'Generosity', 'Perceptions of corruption',
                    'Positive affect', 'Negative affect', 'Economic Freedom', 'Personal Freedom'
                ]
                
                # Imputation par r√©gion et ann√©e
                for column in columns_to_impute:
                    median_values = X_train.groupby(['Regional indicator', 'year'])[column].median()
                    for (regions, year), median in median_values.items():
                        X_train.loc[(X_train['Regional indicator'] == regions) & 
                                   (X_train['year'] == year) & 
                                   (X_train[column].isna()), column] = median
                        X_test.loc[(X_test['Regional indicator'] == regions) & 
                                  (X_test['year'] == year) & 
                                  (X_test[column].isna()), column] = median
    
                # Imputation des valeurs restantes par r√©gion
                for column in columns_to_impute:
                    median_values = X_train.groupby(['Regional indicator'])[column].median()
                    for regions, median in median_values.items():
                        X_train.loc[(X_train['Regional indicator'] == regions) & 
                                   (X_train[column].isna()), column] = median
                        X_test.loc[(X_test['Regional indicator'] == regions) & 
                                  (X_test[column].isna()), column] = median
    
                # Scaling des donn√©es num√©riques
                numeric_cols = columns_to_impute
                scaler = MinMaxScaler(feature_range=(0, 10))
                X_train['year'] = X_train['year'].astype("int")
                X_test['year'] = X_test['year'].astype("int")
                X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
                X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])
    
                # Encoding des variables cat√©gorielles
                columns_to_encode = ['Regional indicator', 'Country name']
                encoder = OneHotEncoder(drop='first', sparse_output=False)
                
                encoded_colstrain = encoder.fit_transform(X_train[columns_to_encode])
                encoded_colstest = encoder.transform(X_test[columns_to_encode])
                
                encoded_col_names = encoder.get_feature_names_out(columns_to_encode)
                
                # Cr√©ation des DataFrames finaux
                encoded_dftrain = pd.DataFrame(encoded_colstrain, columns=encoded_col_names, index=X_train.index)
                encoded_dftest = pd.DataFrame(encoded_colstest, columns=encoded_col_names, index=X_test.index)
                
                remaining_dftrain = X_train.drop(columns=columns_to_encode)
                remaining_dftest = X_test.drop(columns=columns_to_encode)
                
                return pd.concat([encoded_dftrain, remaining_dftrain], axis=1), pd.concat([encoded_dftest, remaining_dftest], axis=1)
    
            # Pr√©traitement des donn√©es
            Xtrain, Xtest = preprocess_data(X_train, X_test)


    
            # Interface utilisateur pour la mod√©lisation
            st.write("### Param√®tres de mod√©lisation")
            
            col1, col2 = st.columns(2)
            with col1:
                model_choice = st.selectbox(
                    "S√©lectionnez un mod√®le",
                    ["Decision Tree","R√©gression Lin√©aire","Random Forest", "XGBoost"], 
                    #format_func=lambda x: "Aucun" if x is None else x
                )
                desactivation_param = st.checkbox("D√©sactiver les param√®tres")
            
            with col2:
                if model_choice in ["Decision Tree", "Random Forest", "XGBoost"] and not desactivation_param:
                    max_depth = st.slider("Profondeur maximale", 1, 10, 3)
                    min_samples_leaf = st.slider("Nombre minimum d'√©chantillons par feuille", 1, 50, 25)
            st.sidebar.markdown('<hr>', unsafe_allow_html=True)
            if model_choice and st.button("Lancer l'entra√Ænement"):
                with st.spinner("Entra√Ænement du mod√®le en cours..."):
                    def train_and_evaluate_model():
                        # S√©lection du mod√®le
                        if model_choice == "R√©gression Lin√©aire":
                            model = LinearRegression()
                        elif model_choice == "Decision Tree" and not desactivation_param:
                            model = DecisionTreeRegressor(max_depth=max_depth, 
                                                       min_samples_leaf=min_samples_leaf, 
                                                       random_state=42)
                        elif model_choice == 'Decision Tree':
                            model = DecisionTreeRegressor(max_depth=3, random_state=42)
                        elif model_choice == 'Random Forest' and not desactivation_param:
                            model = RandomForestRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42, n_estimators=100)
                        elif model_choice == 'Random Forest':
                            model = RandomForestRegressor(max_depth=3, random_state=42, n_estimators=100)
                            
                        elif model_choice == 'XGBoost' and not desactivation_param:
                            model = XGBRegressor(max_depth=max_depth, min_child_weight=min_samples_leaf, random_state=42, n_estimators=100)

                        else: 
                            model = XGBRegressor(max_depth=3, random_state=42, n_estimators=100)

                        st.markdown('<hr>', unsafe_allow_html=True)
                            
                        
                        
                        # Entra√Ænement et pr√©dictions
                        model.fit(Xtrain, y_train)
                        y_pred_train = model.predict(Xtrain)
                        y_pred_test = model.predict(Xtest)
                        
                        return model, y_pred_train, y_pred_test
    
                    # Entra√Ænement et √©valuation du mod√®le
                    model, y_pred_train, y_pred_test = train_and_evaluate_model()



                  # explication
                    if model_choice == "Decision Tree":
                        st.info("""
                        üí° L'importance d'une variable dans un arbre de d√©cision est calcul√©e en fonction de la r√©duction 
                        de l'impuret√© (MSE dans ce cas) qu'elle apporte lors des divisions. Plus une variable permet de 
                        r√©duire l'erreur, plus elle est consid√©r√©e comme importante.
                        """)
                    elif model_choice == "Random Forest":
                        st.info("""
                        üí° Dans un Random Forest, l'importance d'une variable est moyenn√©e sur tous les arbres.
                        Cela donne une estimation plus robuste de l'importance relative de chaque variable pour
                        pr√©dire l'indice de bonheur.
                        """)
                    elif model_choice == "XGBoost":
                        st.info("""
                        üí° Dans XGBoost, l'importance des variables est calcul√©e en fonction de leur contribution
                        √† l'am√©lioration du mod√®le √† chaque boost. Plus une variable est utilis√©e pour faire des
                        splits importants, plus son score d'importance est √©lev√©.
                        """)

          
    
                    # Affichage des m√©triques
                    st.write("### M√©triques de performance")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("MAE Train", 
                                 round(mean_absolute_error(y_train, y_pred_train), 3))
                    with col2:
                        st.metric("MAE Test", 
                                 round(mean_absolute_error(y_test, y_pred_test), 3))
                    with col3:
                        st.metric("R¬≤ Train", 
                                 round(r2_score(y_train, y_pred_train), 3))
                    with col4:
                        st.metric("R¬≤ Test", 
                                 round(r2_score(y_test, y_pred_test), 3))
                        
                    st.markdown('<hr>', unsafe_allow_html=True)
                    
                    # Visualisation des pr√©dictions
                    st.write("### Visualisation des pr√©dictions")
                    fig, ax = plt.subplots(figsize=(8, 6))
                    plt.scatter(y_pred_test, y_test, c='green', alpha=0.5)
                    plt.plot((y_test.min(), y_test.max()), (y_test.min(), y_test.max()), 
                            color='red', linestyle='--')
                    plt.xlabel("Pr√©dictions")
                    plt.ylabel("Valeurs r√©elles")
                    plt.title(f'Life Ladder: Pr√©dictions vs Valeurs r√©elles - {model_choice}')
                    st.pyplot(fig)
    
                    # Importance des variables et visualisation sp√©cifique au mod√®le
                    if model_choice in ["Decision Tree", "Random Forest", "XGBoost"]:
                        main_columns = [
                            'Log GDP per capita', 'Social support', 'Healthy life expectancy at birth',
                            'Freedom to make life choices', 'Generosity', 'Perceptions of corruption',
                            'Positive affect', 'Negative affect', 'Economic Freedom', 'Personal Freedom',
                            'year'
                        ]
                        st.write("### Importance des variables")
                        importances = pd.DataFrame(
                            model.feature_importances_,
                            index=Xtrain.columns,
                            columns=["Importance"]
                        )
                        importances = importances.loc[main_columns].sort_values("Importance", ascending=True)  # Ascending=True pour avoir les plus importantes en haut
                        
                        # On garde les 4 variables les plus importantes
                        top_importances = importances.tail(4)
                        
                        # Cr√©ation du graphique interactif avec Plotly
                        fig = px.bar(
                            top_importances,
                            x='Importance',
                            y=top_importances.index,
                            orientation='h',  
                            title=f"Top 4 variables importantes - {model_choice}",
                            color='Importance',  # Coloration selon l'importance
                            color_continuous_scale='viridis'  
                        )
                        
                        # Personnalisation du graphique
                        fig.update_layout(
                            height=600,
                            yaxis_title="Variables",
                            xaxis_title="Importance relative",
                            showlegend=False,
                            hoverlabel=dict(
                                bgcolor="white",
                                font_size=12,
                                font_family="Arial"
                            ),
                            # Ajout d'annotations pour le pourcentage
                            annotations=[
                                dict(
                                    x=value,
                                    y=idx,
                                    text=f"{value:.1%}",
                                    showarrow=False,
                                    xanchor='left',
                                    xshift=10,
                                    font=dict(size=10)
                                ) for idx, value in zip(top_importances.index, top_importances['Importance'])
                            ]
                        )
                        
                        # Personnalisation des barres
                        fig.update_traces(
                            marker_line_color='black',
                            marker_line_width=1,
                            opacity=0.8,
                            hovertemplate="<b>%{y}</b><br>" +
                                          "Importance: %{x:.1%}<br>" +
                                          "<extra></extra>"  # Nous Supprimons le texte secondaire au survol
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                      

                        ##
                        # Visualisation sp√©cifique au type de mod√®le
                        if model_choice == "Decision Tree":
                            # Code de visualisation de l'arbre
                            st.write("### Visualisation de l'arbre de d√©cision")
                            dot_data = export_graphviz(
                                model,
                                feature_names=list(Xtrain.columns),
                                filled=True,
                                rounded=True,
                                special_characters=True,
                                max_depth=3
                            )
                           
                            
                            # Visualisation matplotlib de l'arbre
                            fig, ax = plt.subplots(figsize=(15, 10))
                            tree.plot_tree(model, 
                                         feature_names=list(Xtrain.columns),
                                         filled=True,
                                         rounded=True,
                                         fontsize=10,
                                         max_depth=3)
                            st.pyplot(fig)
                            
                            # Interpr√©tation une seule fois ici
                            st.write("### Interpr√©tation de l'arbre de d√©cision")
                            st.write("""
                            L'arbre de d√©cision ci-dessus peut √™tre interpr√©t√© comme suit:
                            - Chaque n≈ìud repr√©sente une d√©cision bas√©e sur une variable
                            - Les valeurs dans les n≈ìuds indiquent:
                                - samples: nombre d'√©chantillons dans le n≈ìud
                                - value: la valeur moyenne de l'indice de bonheur
                                - mse: l'erreur quadratique moyenne
                            - Plus la couleur est fonc√©e, plus la valeur pr√©dite est √©lev√©e
                            """)
                        
                        elif model_choice == "Random Forest":
                            st.write("### Visualisation d'un arbre du Random Forest")
                            
                            
                            st.markdown("""
                                <style>
                                    .textorange {
                                        color: #ec5a53;
                                        font-weight: bold;
                                    }
                                </style>
                            """, unsafe_allow_html=True)
                            
                            
                            st.markdown("Le Random Forest est compos√© de plusieurs arbres de d√©cision. Voici la visualisation d'un des arbres de la for√™t (<span class='textorange'>le premier</span>).", unsafe_allow_html=True)


                            
                           
                            
                            fig, ax = plt.subplots(figsize=(15, 10))
                            tree.plot_tree(model.estimators_[0],
                                         feature_names=list(Xtrain.columns),
                                         filled=True,
                                         rounded=True,
                                         fontsize=10,
                                         max_depth=3)
                            st.pyplot(fig)
            
        except Exception as e:
            st.error(f"Une erreur s'est produite lors de la mod√©lisation: {str(e)}")

    
        # ###########           

    
    elif menu == "Analyse Machine Learning":
       st.image("https://myfiteo.app/src_img_happy/img10.png", use_column_width=True)
       st.markdown("<h1>Analyse Machine Learning</h1>", unsafe_allow_html=True)
       #st.markdown("Voici notre rapport sur la mod√©lisation et la pr√©diction", unsafe_allow_html=True)
       st.markdown('<hr>', unsafe_allow_html=True)
       
      
       
       st.markdown("""<br><p align="justify">Au moment de l'entrainement des mod√®les on remarque l'existence d'un surapprentissage. Pour limiter ce probl√®me et optimiser le mod√®le afin qu'il soit le plus performant, nous avons utilis√© un algorithme permettant d'optimiser les param√®tres de chaque mod√®le.
Il convient alors de r√©-entrainer les mod√®les avec ces param√®tres optimis√©s et afficher les m√©triques MAE et R¬≤ pour chaque mod√®le.</p>""",unsafe_allow_html=True)
       st.markdown("""<div style="display: flex; justify-content: center;"> <img src="https://myfiteo.app/src_img_happy/g2.png"/></div><br>""",unsafe_allow_html=True)
       st.info("""
         üí° Il est pratique de pouvoir visuellement analyser les m√©triques de chaque mod√®le.
         - **MAE :**
         XGBoost a une bonne performance en test, mais pr√©sente un risque de surajustement.
         Random Forest semble √©quilibr√©, mais ses erreurs pourraient √™tre r√©duites avec des ajustements d'autres hyperparam√®tres.
         R√©gression lin√©aire montre une bonne robustesse, mais pourrait ne pas capturer la complexit√© des donn√©es.
         Decision Tree est clairement surajust√© aux donn√©es d'entra√Ænement.
        
         - **R¬≤ :**
         Random Forest est plus robuste avec un meilleur √©quilibre entre les ensembles train et test.
         XGBoost est tr√®s performant mais pr√©sente un l√©ger risque de surajustement.
         Regression lin√©aire est un mod√®le robuste et simple.
         Decision Tree est fortement surajust√©, ce qui en fait un mauvais choix sans r√©gularisation ou assemblage.
        
        """)
               #, unsafe_allow_html=True)

        
       st.markdown("""<div style="display: flex; justify-content: center;"> <img src="https://myfiteo.app/src_img_happy/g3.png"/></div>""",unsafe_allow_html=True)
       st.markdown("""<div style="display: flex; justify-content: center;"> <img src="https://myfiteo.app/src_img_happy/g4.png"/></div>""",unsafe_allow_html=True)

       st.write("### Interpr√©tation des r√©sultats")
       st.info("""
       üìä Analyse des performances :
       - **R√©gression lin√©aire** pr√©sente des m√©triques tr√®s proches entre entra√Ænement et test. Ce qui est id√©al pour √©viter le surapprentissage. Ce mod√®le est donc √† privil√©gier.
       - **Random Forest** offre des performances l√©g√®rement sup√©rieures en R2 et en MAE tout en restant √©quilibr√©.
       - **XGBoost** sera privil√©gi√© si la priorit√© est la performance brute et que le surapprentissage peut √™tre att√©nu√© par ajustement d'autres hyperparam√®tres.
       - **Decision Tree** affiche une grande diff√©rence entre les mesures d'entra√Ænement et de test ce qui montre un fort surapprentissage, le rendant le moins fiable. 
       """)
        
       st.markdown("""<br>On peut rapidement remarquer que <b>le PIB</b> est la variable la plus importante du set d'apr√®s la Heatmap pr√©sent√©e et les features importances des mod√®les entrain√©s. <br>Les autres variables ont des r√©sultats tr√®s proches entre elles, ce qui explique cet ordre d'importance diff√©rent.""",unsafe_allow_html=True)
       st.markdown("""<div style="display: flex; justify-content: center;"> <img src="https://myfiteo.app/src_img_happy/g1.png"/></div>""",unsafe_allow_html=True)

       

    if menu == "Conclusion":
                st.image("https://myfiteo.app/src_img_happy/img11.png", use_column_width=True)
                st.markdown("""<h1>Conclusion</h1><hr> """, unsafe_allow_html=True)
                #st.markdown('<hr>', unsafe_allow_html=True)


        
                st.markdown("""
                <style>
                    .textorange {
                        color: #ec5a53;
                        font-weight: regular;
                    }
                    .quote {
                        font-style: italic;
                        font-size: 1.1em;
                    }
                </style>
                <p align="justify">
                    Cette analyse met en √©vidence les principaux facteurs influen√ßant le bonheur √† travers le monde et en Europe. 
                    Les mod√®les pr√©dictifs ont permis de mieux comprendre l'impact des variables sociales, √©conomiques et politiques 
                    sur le bien-√™tre global. <br>
                    Au travers de la DataViz et de la mod√©lisation, il a √©t√© mis en √©vidence que 
                    la richesse par habitant (PIB) d'un pays est le facteur influen√ßant le plus l'indice de bonheur. 
                    <br>Notre analyse pourrait encore √™tre enrichie avec d'autres aspects comme le bien-√™tre au travail, le genre, l'√¢ge des participants, etc. 
                    D'ailleurs, les donn√©es de 2024 qui viennent d'√™tre publi√©es int√®grent une notion de g√©n√©ration.<br>
                    A cet effet, nos recommandations s'adressent aux entreprises qui doivent s'engager dans des pratiques de
                    Responsabilit√© Sociale des Entreprises (RSE). Celles-ci favorisent le bien-√™tre des communaut√©s locales, 
                    contribuant ainsi √† am√©liorer l'aspect positif dans la soci√©t√©, 
                    m√™me dans un contexte d'augmentation du PIB.
                </p>
                
                Comme le dit si bien Emmanuel Kant: 
                <p class="quote">
                    üí° <span class="textorange">"Le concept de bonheur est un concept si ind√©termin√© que, malgr√© le d√©sir qu'√† tout homme d'arriver √† √™tre heureux, 
                    personne ne peut jamais dire ce que r√©ellement il veut et il d√©sire. 
                    Le bonheur est un id√©al non de la raison mais de l'imagination."</span> 
                </p>
                """, unsafe_allow_html=True)


    
    else:
            st.stop()  
